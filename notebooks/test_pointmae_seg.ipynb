{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tlspt.datamodules.components.numpy_dataset import NumpyDataset\n",
    "from tlspt.datamodules.components.base_site import BaseSiteDataset\n",
    "from tlspt.datamodules.components.octree_dataset import OctreeDataset\n",
    "from tlspt.datamodules.components.merged_dataset import MergedOctreeDataset\n",
    "\n",
    "from tlspt.transforms import UniformTLSSampler\n",
    "from tlspt.models.pointmae.pointmae_seg import PointMAESegmentation\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-29 23:53:52.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.datamodules.components.base_site\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mOctreeDataset(../data/plot_octrees/allen-spain/octrees/____TEST.csv, train, 2): reading splits from ../data/plot_octrees/allen-spain/octrees/____TEST.csv\u001b[0m\n",
      "\u001b[32m2024-11-29 23:53:52.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.datamodules.components.base_site\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mOctreeDataset(../data/plot_octrees/allen-spain/octrees/____TEST.csv, train, 2): looking for 1 folders in ../data/plot_octrees/allen-spain/octrees/\u001b[0m\n",
      "\u001b[32m2024-11-29 23:53:52.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.datamodules.components.base_site\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mOctreeDataset(../data/plot_octrees/allen-spain/octrees/____TEST.csv, train, 2): found 1 plots for 'train' out of 1 plots defined in split file\u001b[0m\n",
      "\u001b[32m2024-11-29 23:53:52.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.structures.file_octree\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mInitializing octree from <class 'str'> ../data/plot_octrees/allen-spain/octrees/SPA01_2m/SPA01.json\u001b[0m\n",
      "\u001b[32m2024-11-29 23:53:53.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.utils\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mCreating directory for stats_file ../data/plot_octrees/allen-spain/octrees/stats/stats_1ca57fe9ad288.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "seg_dataset = MergedOctreeDataset(\n",
    "    split_files=['../data/plot_octrees/allen-spain/octrees/____TEST.csv'],\n",
    "    split='train',\n",
    "    scales=[2],\n",
    "    min_points=[512],\n",
    "    feature_names=['scalar_label'],\n",
    "    features_to_normalize=None,\n",
    "    normalize=True,\n",
    "    transform=UniformTLSSampler(num_points=16384)\n",
    "    )\n",
    "\n",
    "seg_dataloader = DataLoader(seg_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-29 23:53:53.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.utils\u001b[0m:\u001b[36mprepare_data\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mreading stats from ../data/plot_octrees/allen-spain/octrees/stats/stats_1ca57fe9ad288.pkl\u001b[0m\n",
      "\u001b[32m2024-11-29 23:53:53.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.utils\u001b[0m:\u001b[36mprepare_data\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mfor dataset OctreeDataset.{'features_to_normalize': None}.train.1ca57fe9ad288\u001b[0m\n",
      "\u001b[32m2024-11-29 23:53:53.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.utils\u001b[0m:\u001b[36mprepare_data\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mmean: tensor([nan])\u001b[0m\n",
      "\u001b[32m2024-11-29 23:53:53.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.utils\u001b[0m:\u001b[36mprepare_data\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mstd: tensor([nan])\u001b[0m\n",
      "\u001b[32m2024-11-29 23:53:53.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.utils\u001b[0m:\u001b[36mprepare_data\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mtorch.float32\u001b[0m\n",
      "\u001b[32m2024-11-29 23:53:53.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.utils\u001b[0m:\u001b[36mprepare_data\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mDataset has 1 features named ['scalar_label']. \n",
      " Normalizing None by mean+std. \u001b[0m\n",
      "\u001b[32m2024-11-29 23:53:53.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtlspt.utils\u001b[0m:\u001b[36mprepare_data\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1m3 channels will be zero centered and scaled to [-1,1].\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "seg_dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'points': tensor([[ 0.1273,  0.1973, -0.0532],\n",
       "         [-0.0376, -0.3053, -0.0085],\n",
       "         [ 0.1211,  0.1789,  0.0530],\n",
       "         ...,\n",
       "         [-0.0525,  0.1358,  0.0539],\n",
       "         [-0.0174, -0.3105, -0.0911],\n",
       "         [-0.0016,  0.2324, -0.0354]]),\n",
       " 'features': tensor([[1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         ...,\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.]]),\n",
       " 'lengths': 3672,\n",
       " 'scales': 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(seg_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['points'].shape\n",
    "batch['features'].shape\n",
    "batch['lengths'].shape\n",
    "batch['scales'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointMAESegmentation(neighbor_alg='ball_query', ball_radius=0.2, scale=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_batch = {'points': batch['points'], 'features': torch.nan_to_num(batch['features']), 'lengths': batch['lengths'], 'scales': batch['scales']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1152, 1]) torch.Size([32, 1152, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7062, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(fix_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 16384\n"
     ]
    }
   ],
   "source": [
    "B, N, _ = batch['points'].shape\n",
    "print(B, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16384, 1])\n",
      "torch.Size([32, 16384])\n"
     ]
    }
   ],
   "source": [
    "x_gt = batch['features']\n",
    "print(x_gt.shape)\n",
    "x_gt = x_gt.squeeze(-1)\n",
    "print(x_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 32, 3])\n",
      "torch.Size([32, 64, 3])\n"
     ]
    }
   ],
   "source": [
    "patches, centers = model.group(\n",
    "    batch['points'], batch['lengths']\n",
    ")\n",
    "print(patches.shape)\n",
    "print(centers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 384])\n",
      "torch.Size([32, 64, 384])\n"
     ]
    }
   ],
   "source": [
    "patch_embeddings = model.patch_encoder(patches)\n",
    "print(patch_embeddings.shape)\n",
    "pos_embeddings = model.pos_encoder(centers)\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 7, 11]\n",
      "===\n",
      "torch.Size([32, 64, 384])\n",
      "[torch.Size([32, 64, 384]), torch.Size([32, 64, 384]), torch.Size([32, 64, 384])]\n"
     ]
    }
   ],
   "source": [
    "x, feature_list = model.transformer_encoder(patch_embeddings, pos_embeddings, feature_blocks=model.feature_blocks)\n",
    "print(model.feature_blocks)\n",
    "print(\"===\")\n",
    "print(x.shape)\n",
    "print([f.shape for f in feature_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1152, 64])\n"
     ]
    }
   ],
   "source": [
    "feature_tensor = torch.cat(feature_list, dim=2)\n",
    "feature_tensor = feature_tensor.transpose(1, 2)\n",
    "print(feature_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1152, 1])\n",
      "torch.Size([32, 1152, 1])\n"
     ]
    }
   ],
   "source": [
    "x_max = torch.max(feature_tensor, dim=2, keepdim=True)[0]\n",
    "x_avg = torch.mean(feature_tensor, dim=2, keepdim=True)\n",
    "print(x_max.shape)\n",
    "print(x_avg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1152, 16384])\n",
      "torch.Size([32, 1152, 16384])\n"
     ]
    }
   ],
   "source": [
    "x_max_feature = x_max.expand(-1, -1, N)\n",
    "x_avg_feature = x_avg.expand(-1, -1, N)\n",
    "print(x_max_feature.shape)\n",
    "print(x_avg_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2304, 16384])\n"
     ]
    }
   ],
   "source": [
    "x_global_feature = torch.cat([x_max_feature, x_avg_feature], dim=1)\n",
    "print(x_global_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_level_0 = model.propagation_0(\n",
    "    batch['points'].transpose(-1, -2), centers.transpose(-1, -2), batch['points'].transpose(-1, -2), feature_tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 16384])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_level_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3328, 16384])\n"
     ]
    }
   ],
   "source": [
    "x = torch.cat(\n",
    "    (f_level_0, x_global_feature), dim=1\n",
    ")\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512, 16384])\n",
      "torch.Size([32, 256, 16384])\n",
      "torch.Size([32, 2, 16384])\n"
     ]
    }
   ],
   "source": [
    "x = model.relu(model.bns1(model.convs1(x)))\n",
    "x = model.dp1(x)\n",
    "print(x.shape)\n",
    "x = model.relu(model.bns2(model.convs2(x)))\n",
    "print(x.shape)\n",
    "x = model.convs3(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16384, 2])\n"
     ]
    }
   ],
   "source": [
    "x_hat = x.transpose(1, 2)\n",
    "print(x_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.get_loss(x_hat, x_gt.long( ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6843, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tlspt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
