wandb:
  project: 2025_tlspt_tune_test
  entity: mja2106
  mode: online
experiment_name: null

hydra:
  run:
    dir: /home/mja78/rds/hpc-work/hydra/${experiment_name}/${now:%Y-%m-%d_%H-%M-%S}
  job:
    chdir: false

devices: 1

max_epochs: 300
strategy: ddp
profiler: null
matmul_precision: 'high'
num_points: 8192
seed: 0

split_files:
  - "${hydra:runtime.cwd}/data/tlspt_labelled/plot_octrees/hjfo-finl/hjfo-finl-splits.csv"
  - "${hydra:runtime.cwd}/data/tlspt_labelled/plot_octrees/hjfo-poll/hjfo-poll-splits.csv"
  - "${hydra:runtime.cwd}/data/tlspt_labelled/plot_octrees/hjfo-spal/hjfo-spal-splits.csv"
min_points: 512
scales: 2
feature_names: ['scalar_truth']

# In your config file
callbacks:
  training_time:
    _target_: tlspt.callbacks.training_time.TrainingTimeCallback
  flops:
    _target_: tlspt.callbacks.flops.FLOPsCallback

no_checkpoint: False

datamodule:
  _target_: tlspt.datamodules.single_datamodule.SingleDataModule
  num_workers: 24
  prefetch_factor: 2
  persistent_workers: True
  pin_memory: True
  batch_size: 16

  limit_train_pct: 1.0
  limit_val_pct: 1.0
  limit_test_pct: 1.0

  train_dataset:
    target_class: tlspt.datamodules.components.merged_dataset.MergedOctreeDataset
    kwargs:
      split_files: ${split_files}
      split: train
      scales: ${scales} #One for each dataset
      min_points: ${min_points} #One for each dataset
      feature_names: ${feature_names}
      features_to_normalize: null
      normalize: True
      transform:
        _target_: tlspt.transforms.UniformTLSSampler
        num_points: ${num_points}

  val_dataset:
    target_class: tlspt.datamodules.components.merged_dataset.MergedOctreeDataset
    kwargs:
      split_files: ${split_files}
      split: val
      scales: ${scales} #One for each dataset
      min_points: ${min_points} #One for each dataset
      feature_names: ${feature_names}
      features_to_normalize: null
      normalize: True
      transform:
        _target_: tlspt.transforms.UniformTLSSampler
        num_points: ${num_points}

  test_dataset:
    target_class: tlspt.datamodules.components.merged_dataset.MergedOctreeDataset
    kwargs:
      split_files: ${split_files}
      split: test
      scales: ${scales} #One for each dataset
      min_points: ${min_points} #One for each dataset
      feature_names: ${feature_names}
      features_to_normalize: null
      normalize: True
      transform:
        _target_: tlspt.transforms.UniformTLSSampler
        num_points: ${num_points}

#VITS
model:
  _target_: tlspt.models.pointmae.pointmae_seg.PointMAESegmentation
  neighbor_alg: ball_query
  ball_radius: 0.2
  scale: 2.0
  total_epochs: ${max_epochs}
  warmup_epochs: 10
  num_centers: 196
  num_neighbors: 64
  embedding_dim: 384 #Width
  transencoder_config:
    embed_dim: ${model.embedding_dim}
    depth: 12 #Depth
    num_heads: 6 #Heads
    mlp_ratio: 4.0 #MLP

gradient_clip_val: 10.0  # Add this line
gradient_clip_algorithm: 'norm'  # Add this line (optional, 'norm' is default)

#VITB
# model:
#   _target_: tlspt.models.pointmae.pointmae_seg.PointMAESegmentation
#   neighbor_alg: ball_query
#   ball_radius: 0.1
#   scale: 2.0
#   total_epochs: ${max_epochs}
#   warmup_epochs: 10
#   num_centers: 196
#   num_neighbors: 64
#   embedding_dim: 768 #Width
#   feature_blocks: Sumfin bigger
#   transencoder_config:
#     embed_dim: ${model.embedding_dim}
#     depth: 12 #Depth
#     num_heads: 12 #Heads
#     mlp_ratio: 4.0 #MLP
